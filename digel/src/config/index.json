{
  "company": {
    "name": "Digel",
    "logo": "/assets/images/logo-light.png"
  },
  "navigation": [
    {
      "name": "Introduction",
      "href": "introduction"
    },
    {
      "name": "Customers",
      "href": "customers"
    },
    {
      "name": "Employees",
      "href": "employees"
    },
    {
      "name": "Latest News",
      "href": "latest-news"
    },
    {
      "name": "About",
      "href": "about"
    }
  ],
  "callToAction": {
    "text": "Get started",
    "href": "#"
  },
  "title": {
    "slogan": "Delivering Industrial Digitalization with Cybernetics Expertise",
    "img": "/assets/images/logo-light.png"
  },
  "introduction": {
    "title": "",
    "items": [
      {
        "title": "About Us",
        "content": [
          "Our team includes engineers with strong backgrounds in cybernetics, robotics, and industrial IT. We have solid expertise in automation systems, covering both Operational Technology (OT) and Information Technology (IT) aspects. Whether it's developing embedded software, designing control systems, working on cloud solutions, or managing frontend development, we can handle it. We also excel in managing large amounts of timeseries data and applying machine learning and AI technologies."
        ],
        "img": ""
      },
      {
        "title": "Project Experience",
        "content": [
          "Our team's wide-ranging industry experience equips us to deliver innovative solutions in various sectors. Examples include: Maritime Operations, Oil & Gas, Aquaculture, Construction, Carbon Capture, Batteries, Shipyards, Electronics, Semiconductors, Agriculture, Wastewater Treatment, Fertilizer Production, and Seaweed Farming."
        ],
        "bold": [
          "Oil",
          "&",
          "Gas",
          "Maritime",
          "Operations",
          "Aquaculture",
          "Construction",
          "Carbon",
          "Capture",
          "Batteries",
          "Shipyards",
          "Electronics",
          "Semiconductors",
          "Agriculture",
          "Wastewater",
          "Treatment",
          "Fertilizer",
          "Production",
          "Seaweed",
          "Farming"
        ],
        "img": ""
      }
    ]
  },
  "customers": {
    "title": "Our Customers and Partners",
    "items": [
      {
        "name": "Aker Solutions",
        "img": "/assets/images/akerSolutions.png",
        "href": "https://www.akersolutions.com/"
      },
      {
        "name": "Hoff",
        "img": "/assets/images/hoff.png",
        "href": "https://www.hoff.no/"
      },
      {
        "name": "Capsol Technologies",
        "img": "/assets/images/capsol.png",
        "href": "https://www.capsoltechnologies.com/"
      },
      {
        "name": "RunwayFBU",
        "img": "/assets/images/runwayFBU.svg",
        "href": "https://runwayfbu.com/"
      }
    ]
  },
  "employees": {
    "title": "Meet the Team!",
    "items": [
      {
        "name": "Christoffer Lange | CEO",
        "role": "",
        "img": "/assets/images/christoffer-2.png",
        "description": "M.Sc. Engineering & ICT, Norwegian University of Science and Technology",
        "keywords": ["Tech Lead", "Engineerng Automation", "Industrial IoT"]
      },
      {
        "name": "Thomas Andersen",
        "role": "",
        "img": "/assets/images/thomas-2.png",
        "description": "M.Sc. Cybernetics & Robotics, Norwegian University of Science and Technology",
        "keywords": ["Cloud", "Embedded", "Machine Learning"]
      },
      {
        "name": "Axel Bech",
        "role": "",
        "img": "/assets/images/axel-2.png",
        "description": "M.Sc. Cybernetics & Robotics, Norwegian University of Science and Technology",
        "keywords": ["Fullstack", "Modeling", "Optimization"]
      },
      {
        "name": "Vegard Sanden",
        "role": "",
        "img": "/assets/images/vegard.png",
        "description": "M.Sc. Cybernetics & Robotics, Norwegian University of Science and Technology",
        "keywords": ["Fullstack", "Modeling", "Cloud"]
      },
      {
        "name": "Erlend Blomseth",
        "role": "",
        "img": "/assets/images/erlend-2.png",
        "description": "M.Sc. Cybernetics & Robotics, Norwegian University of Science and Technology",
        "keywords": ["Fullstack", "Architect"]
      },
      {
        "name": "Bjørn-Erik Dale | Chairman",
        "role": "",
        "img": "/assets/images/bjorn-erik.png",
        "description": "M.Sc. Industrial Economics & Technology Management, Norwegian University of Science and Technology",
        "keywords": []
      }
    ]
  },
  "blog": {
    "title": "Latest News",
    "posts": [
      {
        "title": "Helping Hoff SA Reduce Waste and Optimize Potato Processing",
        "img": "/assets/images/erlend-pa-hoff.jpg",
        "author": {
          "name": "Christoffer Lange",
          "src": "/assets/images/christoffer-2.png"
        },
        "published": "Jun 13, 2025",
        "sections": [
          {
            "content": "Hoff SA is Norway’s largest potato processor, handling vast volumes of raw material from farms across the country. With multiple production lines running in parallel, visibility and control are essential to reducing waste and ensuring consistent quality."
          },
          {
            "content": "Together with Hoff, Digel has developed digital tools that provide real-time insight and help turn production data into better decisions."
          },
          {
            "title": "The Challenge: Seeing the Full Picture",
            "content": "In modern food production, small variations can have large consequences. Raw material quality, operator experience, and machine settings all affect the final product. Hoff needed a way to understand how these variables interact."
          },
          {
            "content": "Much of the knowledge in production today lives in the heads of experienced operators. Adjustments are made based on intuition rather than data, leading to inconsistencies in resource use and product quality. Our goal is to enable decisions based on shared, trusted data."
          },
          {
            "title": "The Solution: From Data to Insight",
            "content": "Digel helped Hoff collect and visualize data across systems and production stages. This includes:"
          },
          {
            "content": "• Real-time silo overviews with volume, raw material quality and origin"
          },
          {
            "content": "• Traceability across intake, production lines, and quality checks"
          },
          {
            "content": "• Dashboards comparing shifts and lines, giving production leads clear insight"
          },
          {
            "img": {
              "src": "/assets/images/espen-med-pomfri.jpg",
              "caption": "“We now base our discussions on facts, not just gut feeling. That makes a real difference in day-to-day decisions.” - Espen Slåtten, Technical Director at Hoff"
            }
          },
          {
            "title": "A Common Industry Problem",
            "content": "Many potato processors face the same challenges: variation in raw material, manual control, and limited visibility. Our work with Hoff shows how better use of existing data can improve both performance and predictability."
          },
          {
            "title": "What’s Next: Experience-Based Process Control",
            "content": "With the right data in place, the next step is to set process parameters based on full context; raw material, historical outcomes, environment and operations. This will allow for smarter adjustments and more consistent results over time."
          }
        ]
      },
      {
        "title": "Streamlining Engineering at Aker Solutions",
        "img": "/assets/images/chris-axel.jpg",
        "author": {
          "name": "Christoffer Lange",
          "src": "/assets/images/christoffer-2.png"
        },
        "published": "Apr 3, 2024",
        "sections": [
          {
            "content": "Digel is working with Aker Solutions to advance engineering processes, particularly in the design of stair towers for offshore installations."
          },
          {
            "title": "Project Overview",
            "content": "The application reduces the traditional design time for stair towers from several weeks to a few minutes. Using Python and the ParaPy framework, it automates the complex design process, while ensuring each stair tower is structurally sound and ergonomically efficient for safe use by offshore personnel. Additionally, the application integrates seamlessly with E3D from Aveva, a 3D design software used extensively in process and power plant engineering."
          },
          {
            "title": "Digel's Role",
            "content": "Our contribution includes software development and project management. Digel utilizes our industrial expertise and knowledge of both traditional engineering and software competencies to effectively address specific engineering challenges.",
            "img": {
              "src": "/assets/images/axel-christoffer-aker-2.jpg",
              "caption": "'It is inherent in Digel's nature to engage in processes that drive disruptive changes in industrial operations', says Christoffer, reflecting on the core philosophy that guides our work."
            }
          },
          {
            "title": "Conclusion",
            "content": "The collaborative efforts between Digel and Aker Solutions demonstrate the benefits of applying modern software solutions to streamline complex engineering tasks, setting new standards for efficiency and innovation in the industry. To achieve truly disruptive changes, it is essential to possess expertise not only in engineering but also in IT. Mastery of both disciplines is key to realizing the real benefits of digitalization."
          }
        ]
      },
      {
        "title": "An Introduction to Reinforcement Learning: What is it, and what can it be used for?",
        "author": {
          "name": "Thomas Andersen",
          "src": "/assets/images/thomas-2.png"
        },
        "img": "/assets/images/rl-intro-blog-post.webp",
        "published": "May 5, 2024",
        "sections": [
          {
            "content": "Are you curious about how machines can learn by experience and improve over time? At Digel, we believe that Reinforcement Learning (RL) can be the key framework for optimizing industrial processes. In this blog post, I will give you a simple introduction to RL, how it works, what separates it from other machine learning methods, and some use cases."
          },
          {
            "title": "The Three Classes of Machine Learning",
            "content": "Within the world of machine learning (ML), we typically categorize methods of learning into three classes: supervised learning, unsupervised learning, and RL."
          },
          {
            "content": "In supervised learning, a dataset that maps inputs to correct outputs is used for training the AI agent. Supervised learning is often used for image classification, e.g., classifying animals in pictures. The dataset used to train the animal-classifying agent will typically consist of images of a broad range of species, each individually labeled with the species name. This is why we call it supervised learning since the learning process is guided by a 'supervisor' that provides correct answers for each example in the training data. The AI agent learns to associate input images with the correct labels through this process, improving its accuracy over time."
          },
          {
            "content": "On the other hand, unsupervised learning is a set of methods that try to identify patterns and relationships within the data. A typical unsupervised learning approach is clustering techniques, i.e., grouping similar data points together. If we continue with our dataset of animal species, we may reformulate the classification problem to an unsupervised learning problem where we find similarities between species from the images without prior knowledge of the animal names."
          },
          {
            "content": "With RL, the AI agent learns by interacting with its environment. The agent receives feedback from the environment in the form of rewards or penalties based on its actions. Through trial and error, the agent aims to maximize its rewards over time (and minimize penalties) to find an optimal action to take at any given state. Continuing with our animal-themed examples, we might want to try to train an RL agent to survive in nature. The agent will receive a reward for every encounter with an animal where the agent stays alive and will receive a penalty for encounters with predators that eat the agent. By simulating enough encounters with different species, the agent will learn to avoid a set of species.",
            "img": {
              "src": "/assets/images/rl-intro-architecture-blog-post.jpg",
              "caption": "The basic components of all reinforcement learning architectures consists of an agent interacting with an environment."
            }
          },
          {
            "title": "RL vs. Control Theory",
            "content": "As exemplified in the last paragraph, RL agents are trained to make sequences of actions that maximize some notion of cumulative reward. In reinforcement learning literature, one often refers to the decision-making function as the agent's policy. The goal is to optimize the policy in such a way that maximizes the agent's reward when interacting with the environment. In other words, the problems solved by RL may also be phrased as control problems. The policy that is continuously updated for each simulation cycle may be viewed as the control law used for making optimized actions in the environment. The main difference between traditional control theory and reinforcement learning is that RL involves adaptive learning from interactions, while control theory usually involves pre-designed controllers based on system models. It is due to reinforcement learning's trial-and-error approach to finding optimal policies that reinforcement learning excels in complex, uncertain, dynamic environments where learning from experience is crucial."
          },
          {
            "title": "Where is RL used today?",
            "content": "Reinforcement learning is for instance used in e-commerce to enhance suggestion systems. By analyzing user behavior and feedback, RL algorithms can learn to suggest products that are more likely to interest the user, thereby improving user experience and increasing sales. For example, an RL-based recommendation system might suggest new products based on past purchases and browsing history, continually refining its suggestions as it learns more about user preferences."
          },
          {
            "content": "In the gaming industry, reinforcement learning has led to significant advancements, particularly in developing sophisticated game AI. AlphaGO, developed by DeepMind, is a prime example where RL enabled the AI to master the complex game of Go, even defeating world champions. Similarly, RL techniques have been applied to Atari games, allowing AI agents to learn and master these games through trial and error, often achieving superhuman performance.",
            "img": {
              "src": "/assets/images/rl-intro-go-blog-post.jpg",
              "caption": "AlphaGo by Deepmind utilized reinforcement learning methods to beat the top go player Lee Sedol."
            }
          },
          {
            "content": "RL approaches are also trending in robotics and the development of autonomous vehicles. In robotics, RL is used to teach robots how to perform complex tasks such as object manipulation, navigation, and human-robot interaction. For autonomous vehicles, RL helps in decision-making processes, enabling the vehicle to navigate through dynamic environments, avoid obstacles, and optimize routes based on real-time data."
          },
          {
            "content": "Generative AI models, such as those used for creating art, music, or text, benefit from RL by incorporating human feedback to refine their outputs. RL allows these models to adjust their generation strategies based on the rewards or penalties received from human interactions. This approach leads to more nuanced and higher-quality outputs that align better with human preferences and creativity."
          },
          {
            "title": "Future usage of RL",
            "content": "I suspect that RL will become increasingly influential in various industrial sectors over the coming years, particularly in areas such as energy, industrial processes, and manufacturing."
          },
          {
            "content": "In the energy sector, RL can optimize the management of smart grids and renewable energy sources. By learning from real-time data, RL algorithms can enhance energy efficiency, reduce costs, and ensure reliable energy distribution. For instance, RL can dynamically adjust the supply-demand balance in smart grids, optimize the operation of wind and solar power plants, and improve energy storage systems. RL's ability to adapt to real-time changes and optimize decisions in complex environments makes it particularly useful in the energy sector, where conditions and demand can fluctuate rapidly."
          },
          {
            "content": "RL has the potential to transform industrial processes, including carbon capture and utilization. RL algorithms can optimize the parameters of carbon capture systems to maximize efficiency and minimize costs. By learning from operational data, RL can enhance the performance of carbon capture technologies, making them more effective in reducing greenhouse gas emissions. RL's adaptive learning capabilities allow it to handle the complexities and variabilities inherent in distributed industrial processes, leading to more efficient and sustainable operations."
          },
          {
            "content": "In manufacturing, RL can be applied across various stages of the production line, from assembly to maintenance. RL algorithms can help robots learn new tasks, optimize workflows, and ensure precision in repetitive tasks. Predictive maintenance powered by RL can foresee equipment malfunctions, schedule timely interventions, and prevent costly breakdowns. This not only enhances efficiency but also extends the lifespan of machinery. The trial-and-error approach of RL enables continuous improvement and adaptation to changing conditions, making it invaluable in dynamic manufacturing environments."
          },
          {
            "title": "Conclusion",
            "content": "Reinforcement Learning is a powerful machine learning framework that learns and improves over time by interacting with the environment. It has huge potential to solve complex problems and adapt to dynamic situations. Stay tuned for future blog posts where we will delve deeper into the fascinating world of RL!"
          }
        ]
      }
    ]
  },
  "about": {
    "sections": [
      {
        "name": "E-mail",
        "content": "hello@digel.io"
      },
      {
        "name": "Phone number",
        "content": "+47 95744191"
      },
      {
        "name": "Organization number",
        "content": "933 191 656"
      }
    ],
    "socialMedia": {
      "github": "https://github.com/digel-as",
      "linkedin": "https://www.linkedin.com/company/102369767"
    }
  }
}
